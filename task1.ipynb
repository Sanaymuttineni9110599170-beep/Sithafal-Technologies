{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'downloaded_pdf.pdf'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def download_pdf(url, filename):\n",
    "    response = requests.get(url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    return filename\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.hunter.cuny.edu/dolciani/pdf_files/workshop-materials/mmc-presentations/tables-charts-and-graphs-with-examples-from.pdf\"\n",
    "filename = \"downloaded_pdf.pdf\"\n",
    "download_pdf(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables, Charts, and \n",
      "Graphs \n",
      "with Examples from History, Economics, \n",
      "Education, Psychology, Urban Affairs and \n",
      "Everyday Life\n",
      "REVISED: MICHAEL LOLKUS 2018\n",
      "Tables, Charts, and \n",
      "Graphs Basics\n",
      "We use charts and graphs to visualize data.  \n",
      "This data can either be generated data, data gathered from \n",
      "an experiment, or data collected from some source.\n",
      "A picture tells a thousand words so it is not a surprise that \n",
      "many people use charts and graphs when explaining data.\n",
      "Types of Visual \n",
      "Representations of Data\n",
      "Table of Yearly U.S. GDP by \n",
      "Industry (in millions of dollars)\n",
      "Year\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "All Industries\n",
      "26093515\n",
      "27535971\n",
      "28663246\n",
      "29601191\n",
      "30895407\n",
      "31397023\n",
      "Manufacturing\n",
      "4992521\n",
      "5581942\n",
      "5841608\n",
      "5953299\n",
      "6047477\n",
      "5829554\n",
      "Finance,\n",
      "Insurance, Real \n",
      "Estate, Rental, \n",
      "Leasing\n",
      "4522451\n",
      "4618678\n",
      "4797313\n",
      "5031881\n",
      "5339678\n",
      "5597018\n",
      "Arts, \n",
      "Entertainment, \n",
      "Recreation, \n",
      "Accommodation,\n",
      "and Food Service\n",
      "964032\n",
      "1015238\n",
      "1076249\n",
      "1120496\n",
      "1189646\n",
      "1283813\n",
      "Other\n",
      "15614511\n",
      "16320113\n",
      "16948076\n",
      "17495515\n",
      "183186\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)  # Open the PDF\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")  # Extract text from each page\n",
    "    return text\n",
    "\n",
    "# Extract text from the downloaded PDF\n",
    "pdf_text = extract_text_from_pdf(filename)\n",
    "print(pdf_text[:1000])  # Print the first 1000 characters of extracted text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 11\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, chunk_size=500):\n",
    "    \"\"\"Chunk the text into smaller pieces.\"\"\"\n",
    "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(pdf_text)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (11, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def embed_text_chunks(chunks):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # A lightweight transformer model\n",
    "    embeddings = model.encode(chunks)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = embed_text_chunks(chunks)\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def create_faiss_index(embeddings):\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])  # Index for L2 similarity\n",
    "    index.add(np.array(embeddings))  # Add embeddings to the index\n",
    "    return index\n",
    "\n",
    "index = create_faiss_index(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matching chunk indices: [[2 1 5]]\n"
     ]
    }
   ],
   "source": [
    "def search_query(query, index, model, top_k=3):\n",
    "    query_embedding = model.encode([query])\n",
    "    _, indices = index.search(np.array(query_embedding), top_k)\n",
    "    return indices\n",
    "\n",
    "query = \"What is the unemployment rate based on degree?\"\n",
    "relevant_indices = search_query(query, index, model)\n",
    "print(f\"Top matching chunk indices: {relevant_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Degree': [\"Bachelor's\", \"Master's\"], 'Unemployment Rate': [5.3, 3.8]}\n"
     ]
    }
   ],
   "source": [
    "def compare_data(data1, data2):\n",
    "    # Assuming you have extracted relevant data (could be unemployment rates or table rows)\n",
    "    comparison = {\n",
    "        \"Degree\": [data1[\"degree\"], data2[\"degree\"]],\n",
    "        \"Unemployment Rate\": [data1[\"unemployment_rate\"], data2[\"unemployment_rate\"]],\n",
    "    }\n",
    "    return comparison\n",
    "\n",
    "# Example usage\n",
    "data1 = {\"degree\": \"Bachelor's\", \"unemployment_rate\": 5.3}\n",
    "data2 = {\"degree\": \"Master's\", \"unemployment_rate\": 3.8}\n",
    "comparison_result = compare_data(data1, data2)\n",
    "print(comparison_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Make sure you have your OpenAI API key set\n",
    "openai.api_key = \"Seceret_API_Key\"\n",
    "\n",
    "def generate_response(retrieved_data, query):\n",
    "    # Construct the prompt using the retrieved data and the user's query\n",
    "    prompt = f\"Answer the following question using the provided data: {query}\\n\\n{retrieved_data}\"\n",
    "    \n",
    "    # Send the prompt to OpenAI's GPT model\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",  # You can use other engines like \"gpt-4\" if available\n",
    "        prompt=prompt,\n",
    "        max_tokens=200  # Limit the length of the response\n",
    "    )\n",
    "    \n",
    "    # Return the text generated by the model\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Example usage\n",
    "query = \"What is the unemployment rate based on degree?\"\n",
    "retrieved_data = \"Bachelor's degree has an unemployment rate of 5.3%.\"\n",
    "\n",
    "response = generate_response(retrieved_data, query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"Secret_API_Key\"\n",
    "try:\n",
    "    # Make a simple request to check the API key validity\n",
    "    models = openai.Model.list()  # List available models\n",
    "    print(\"API Key is valid. Models available:\", models)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
